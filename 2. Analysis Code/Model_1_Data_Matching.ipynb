{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code : (1) 금융 데이터 매칭 패턴 모델링**\n",
    "\n",
    "- Project : 2024 데이터바우처 지원사업\n",
    "- Writer : Donghyeon Kim\n",
    "- Update : 2024.10.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **0. 라이브러리 및 초기 경로 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = 'C:/'\n",
    "folder_1 = 'Users/USER/Dropbox/8. 회사업무/1. 산학협력프로젝트/2024년/9. [선정] 2024 데이터바우처 지원사업(경리법인일조)/7. 분석'\n",
    "root = dr + folder_1\n",
    "\n",
    "folder_2 = '1_rawdata'\n",
    "folder_path = root + '/' + folder_2\n",
    "\n",
    "os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사이름\n",
    "company_name = os.listdir()[6] # Available Index : 0 ~ 9 (Total : 10)\n",
    "\n",
    "# 회사이름 포함 경로\n",
    "final_path = folder_path + '/' + company_name\n",
    "os.chdir(final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. 입금내역 Data Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>입금일자</th>\n",
       "      <th>은행</th>\n",
       "      <th>입금액</th>\n",
       "      <th>용도</th>\n",
       "      <th>내용</th>\n",
       "      <th>프로젝트/현장</th>\n",
       "      <th>비고</th>\n",
       "      <th>메모</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>660000</td>\n",
       "      <td>매출대금입금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-23 세계2023-12-28 세계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>330000</td>\n",
       "      <td>매출대금입금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-20 세계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>2607000</td>\n",
       "      <td>매출대금입금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-30 세계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>2200000</td>\n",
       "      <td>매출대금입금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-27 세계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>440000</td>\n",
       "      <td>매출대금입금</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 세계</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           입금일자    은행      입금액      용도   내용  프로젝트/현장  \\\n",
       "105  2023-12-29  우리은행   660000  매출대금입금  NaN      NaN   \n",
       "106  2023-12-28  우리은행   330000  매출대금입금  NaN      NaN   \n",
       "107  2023-12-28  우리은행  2607000  매출대금입금  NaN      NaN   \n",
       "108  2023-12-28  우리은행  2200000  매출대금입금  NaN      NaN   \n",
       "109  2023-12-19  우리은행   440000  매출대금입금  NaN      NaN   \n",
       "\n",
       "                             비고  메모  \n",
       "105  2023-11-23 세계2023-12-28 세계 NaN  \n",
       "106               2023-12-20 세계 NaN  \n",
       "107               2023-11-30 세계 NaN  \n",
       "108               2023-12-27 세계 NaN  \n",
       "109               2023-12-19 세계 NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '입금내역_수납확인' 파일명\n",
    "file_name = [file for file in os.listdir() if '입금내역_수납확인' in file] # 입금내역 파일 1개\n",
    "\n",
    "# Data Frame\n",
    "df = pd.read_excel(file_name[0], skiprows=1)\n",
    "\n",
    "# Data Frame Head(2023)\n",
    "df_without_account = df.drop(columns=['계좌번호', '계좌적요', '거래처'])\n",
    "df_without_account[df_without_account['입금일자'].str.contains('2023-12')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1) 입금 파일 : '용도' Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Progress:\n",
      "[0]\tvalidation_0-mlogloss:0.99415\n",
      "[1]\tvalidation_0-mlogloss:0.69669\n",
      "[2]\tvalidation_0-mlogloss:0.51397\n",
      "[3]\tvalidation_0-mlogloss:0.38901\n",
      "[4]\tvalidation_0-mlogloss:0.29362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalidation_0-mlogloss:0.22794\n",
      "[6]\tvalidation_0-mlogloss:0.17536\n",
      "[7]\tvalidation_0-mlogloss:0.13705\n",
      "[8]\tvalidation_0-mlogloss:0.10929\n",
      "[9]\tvalidation_0-mlogloss:0.08871\n",
      "[10]\tvalidation_0-mlogloss:0.07286\n",
      "[11]\tvalidation_0-mlogloss:0.06073\n",
      "[12]\tvalidation_0-mlogloss:0.05089\n",
      "[13]\tvalidation_0-mlogloss:0.04325\n",
      "[14]\tvalidation_0-mlogloss:0.03792\n",
      "[15]\tvalidation_0-mlogloss:0.03386\n",
      "[16]\tvalidation_0-mlogloss:0.03062\n",
      "[17]\tvalidation_0-mlogloss:0.02811\n",
      "[18]\tvalidation_0-mlogloss:0.02611\n",
      "[19]\tvalidation_0-mlogloss:0.02495\n",
      "[20]\tvalidation_0-mlogloss:0.02398\n",
      "[21]\tvalidation_0-mlogloss:0.02315\n",
      "[22]\tvalidation_0-mlogloss:0.02266\n",
      "[23]\tvalidation_0-mlogloss:0.02231\n",
      "[24]\tvalidation_0-mlogloss:0.02202\n",
      "[25]\tvalidation_0-mlogloss:0.02188\n",
      "[26]\tvalidation_0-mlogloss:0.02179\n",
      "[27]\tvalidation_0-mlogloss:0.02177\n",
      "[28]\tvalidation_0-mlogloss:0.02179\n",
      "[29]\tvalidation_0-mlogloss:0.02182\n",
      "[30]\tvalidation_0-mlogloss:0.02186\n",
      "[31]\tvalidation_0-mlogloss:0.02191\n",
      "[32]\tvalidation_0-mlogloss:0.02197\n",
      "[33]\tvalidation_0-mlogloss:0.02194\n",
      "[34]\tvalidation_0-mlogloss:0.02199\n",
      "[35]\tvalidation_0-mlogloss:0.02206\n",
      "[36]\tvalidation_0-mlogloss:0.02217\n",
      "[37]\tvalidation_0-mlogloss:0.02217\n",
      "[38]\tvalidation_0-mlogloss:0.02218\n",
      "[39]\tvalidation_0-mlogloss:0.02219\n",
      "[40]\tvalidation_0-mlogloss:0.02221\n",
      "[41]\tvalidation_0-mlogloss:0.02228\n",
      "[42]\tvalidation_0-mlogloss:0.02211\n",
      "[43]\tvalidation_0-mlogloss:0.02213\n",
      "[44]\tvalidation_0-mlogloss:0.02210\n",
      "[45]\tvalidation_0-mlogloss:0.02209\n",
      "[46]\tvalidation_0-mlogloss:0.02197\n",
      "[47]\tvalidation_0-mlogloss:0.02199\n",
      "[48]\tvalidation_0-mlogloss:0.02202\n",
      "[49]\tvalidation_0-mlogloss:0.02187\n",
      "[50]\tvalidation_0-mlogloss:0.02191\n",
      "[51]\tvalidation_0-mlogloss:0.02180\n",
      "[52]\tvalidation_0-mlogloss:0.02189\n",
      "[53]\tvalidation_0-mlogloss:0.02192\n",
      "[54]\tvalidation_0-mlogloss:0.02181\n",
      "[55]\tvalidation_0-mlogloss:0.02185\n",
      "[56]\tvalidation_0-mlogloss:0.02174\n",
      "[57]\tvalidation_0-mlogloss:0.02178\n",
      "[58]\tvalidation_0-mlogloss:0.02181\n",
      "[59]\tvalidation_0-mlogloss:0.02187\n",
      "[60]\tvalidation_0-mlogloss:0.02177\n",
      "[61]\tvalidation_0-mlogloss:0.02177\n",
      "[62]\tvalidation_0-mlogloss:0.02185\n",
      "[63]\tvalidation_0-mlogloss:0.02175\n",
      "[64]\tvalidation_0-mlogloss:0.02175\n",
      "[65]\tvalidation_0-mlogloss:0.02183\n",
      "[66]\tvalidation_0-mlogloss:0.02173\n",
      "[67]\tvalidation_0-mlogloss:0.02173\n",
      "[68]\tvalidation_0-mlogloss:0.02170\n",
      "[69]\tvalidation_0-mlogloss:0.02172\n",
      "[70]\tvalidation_0-mlogloss:0.02169\n",
      "[71]\tvalidation_0-mlogloss:0.02176\n",
      "[72]\tvalidation_0-mlogloss:0.02167\n",
      "[73]\tvalidation_0-mlogloss:0.02174\n",
      "[74]\tvalidation_0-mlogloss:0.02165\n",
      "[75]\tvalidation_0-mlogloss:0.02165\n",
      "[76]\tvalidation_0-mlogloss:0.02173\n",
      "[77]\tvalidation_0-mlogloss:0.02164\n",
      "[78]\tvalidation_0-mlogloss:0.02170\n",
      "[79]\tvalidation_0-mlogloss:0.02162\n",
      "[80]\tvalidation_0-mlogloss:0.02169\n",
      "[81]\tvalidation_0-mlogloss:0.02164\n",
      "[82]\tvalidation_0-mlogloss:0.02165\n",
      "[83]\tvalidation_0-mlogloss:0.02164\n",
      "[84]\tvalidation_0-mlogloss:0.02169\n",
      "[85]\tvalidation_0-mlogloss:0.02164\n",
      "[86]\tvalidation_0-mlogloss:0.02170\n",
      "[87]\tvalidation_0-mlogloss:0.02165\n",
      "[88]\tvalidation_0-mlogloss:0.02160\n",
      "[89]\tvalidation_0-mlogloss:0.02165\n",
      "[90]\tvalidation_0-mlogloss:0.02161\n",
      "[91]\tvalidation_0-mlogloss:0.02167\n",
      "[92]\tvalidation_0-mlogloss:0.02160\n",
      "[93]\tvalidation_0-mlogloss:0.02164\n",
      "[94]\tvalidation_0-mlogloss:0.02162\n",
      "[95]\tvalidation_0-mlogloss:0.02155\n",
      "[96]\tvalidation_0-mlogloss:0.02161\n",
      "[97]\tvalidation_0-mlogloss:0.02154\n",
      "[98]\tvalidation_0-mlogloss:0.02160\n",
      "[99]\tvalidation_0-mlogloss:0.02153\n",
      "RandomForest Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest Training: 100%|██████████| 100/100 [00:11<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# '입금일자'를 datetime 형식으로 변환하고 2023년까지 필터링\n",
    "df['입금일자'] = pd.to_datetime(df['입금일자'], errors='coerce')\n",
    "df_filtered = df[df['입금일자'].dt.year <= 2023].copy()\n",
    "\n",
    "# '용도'와 '거래처'의 결측치가 있는 행 제거\n",
    "df_filtered_cleaned = df_filtered.dropna(subset=['용도', '거래처']).copy()\n",
    "\n",
    "# 예측에 사용할 특성 선택\n",
    "df_features = df_filtered_cleaned[['입금액', '계좌적요', '은행', '용도', '거래처']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거\n",
    "df_features_cleaned = df_features.dropna().copy()\n",
    "\n",
    "# 클래스별 데이터 개수 확인\n",
    "class_counts = df_features_cleaned['용도'].value_counts()\n",
    "\n",
    "# 클래스 수가 2개 미만인 클래스 제거\n",
    "min_class_count = 2\n",
    "classes_to_keep = class_counts[class_counts >= min_class_count].index\n",
    "df_filtered_cleaned = df_features_cleaned[df_features_cleaned['용도'].isin(classes_to_keep)].copy()\n",
    "\n",
    "# 다시 X와 y 정의\n",
    "X = df_filtered_cleaned[['입금액', '계좌적요', '은행']].copy()\n",
    "y = df_filtered_cleaned['용도'].copy()\n",
    "\n",
    "# 범주형 변수(Label Encoding) 변환 (클래스 제거 후 적용)\n",
    "label_encoder_계좌적요 = LabelEncoder()\n",
    "label_encoder_은행 = LabelEncoder()\n",
    "label_encoder_용도 = LabelEncoder()\n",
    "\n",
    "# Fit Transform\n",
    "X['계좌적요'] = label_encoder_계좌적요.fit_transform(X['계좌적요'].copy())\n",
    "X['은행'] = label_encoder_은행.fit_transform(X['은행'].copy())\n",
    "y = label_encoder_용도.fit_transform(y.copy())\n",
    "\n",
    "# 데이터셋을 stratify를 사용해 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 클래스 불균형 문제를 해결하기 위해 Random Over Sampling 적용\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링한 학습 데이터에서 20%를 검증 데이터로 분리 (eval_set용)\n",
    "X_train_ros, X_val_ros, y_train_ros, y_val_ros = train_test_split(\n",
    "    X_train_ros, y_train_ros, test_size=0.2, random_state=42, stratify=y_train_ros\n",
    ")\n",
    "\n",
    "# XGBoost 모델 학습 (eval_set을 사용해 성능 모니터링)\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss')\n",
    "\n",
    "print('XGBoost Training Progress:')\n",
    "xgb_model.fit(X_train_ros, y_train_ros, eval_set=[(X_val_ros, y_val_ros)])\n",
    "\n",
    "# RandomForest 모델 학습 시 tqdm 진행률 표시\n",
    "n_estimators = 100\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "print('RandomForest Training Progress:')\n",
    "for i in tqdm(range(1, n_estimators + 1), desc='RandomForest Training'):\n",
    "    rf_model.set_params(n_estimators=i)\n",
    "    rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Voting Classifier 생성 (XGBoost + RandomForest)\n",
    "voting_clf = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "# Voting Classifier 학습 시 tqdm 진행률 표시\n",
    "print('Voting Classifier Training Progress:')\n",
    "for _ in tqdm(range(1), desc='Voting Classifier Training'):\n",
    "    voting_clf.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "# XGBoost + RandomForest Ensemble Result\n",
    "# LabelEncoder로 예측된 값을 다시 원래 값으로 디코딩\n",
    "y_test_original = label_encoder_용도.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder_용도.inverse_transform(y_pred)\n",
    "\n",
    "# Classification_report를 Dictionary로 변환\n",
    "report = classification_report(y_test_original, y_pred_original, zero_division=1, output_dict=True)\n",
    "\n",
    "# Accuracy만 출력\n",
    "accuracy = round(report['accuracy'], 3)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# classification_report를 데이터프레임으로 변환하고 엑셀로 저장하는 간단한 코드\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 소수점 3자리로 변환\n",
    "report_df = report_df.round(3)\n",
    "\n",
    "# 회사명에 따른 결과물 저장 경로\n",
    "result_root = os.path.join(root, 'Model(1st)')\n",
    "company_result_root = os.path.join(result_root, company_name)\n",
    "if not os.path.isdir(company_result_root):\n",
    "    os.makedirs(company_result_root)\n",
    "\n",
    "# 결과물 최종 경로\n",
    "output_file = os.path.join(company_result_root, f'{company_name}_입금내역_용도.xlsx')\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "report_df.to_excel(output_file, index=True)\n",
    "print('Classification Report가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 예측 결과가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2024년 Data 예측 #\n",
    "\n",
    "# '입금일자'를 datetime 형식으로 변환하고 2024년 필터링\n",
    "df_2024 = df[df['입금일자'].dt.year == 2024].copy()\n",
    "\n",
    "# 예측에 필요한 컬럼만 선택\n",
    "df_2024_features = df_2024[['입금액', '계좌적요', '은행']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거 (원본 데이터에서 인덱스 추적)\n",
    "df_2024_features_cleaned = df_2024_features.dropna().copy()\n",
    "df_2024_cleaned = df_2024.loc[df_2024_features_cleaned.index].copy()\n",
    "\n",
    "# 라벨 인코딩 (기존에 학습된 인코더 사용)\n",
    "# 새로운 값을 처리하기 위해 np.where를 사용해 학습 데이터에 없는 값은 \"기타\"로 처리\n",
    "df_2024_features_cleaned['계좌적요'] = np.where(\n",
    "    df_2024_features_cleaned['계좌적요'].isin(label_encoder_계좌적요.classes_),\n",
    "    df_2024_features_cleaned['계좌적요'],\n",
    "    '기타'\n",
    ")\n",
    "df_2024_features_cleaned['은행'] = np.where(\n",
    "    df_2024_features_cleaned['은행'].isin(label_encoder_은행.classes_),\n",
    "    df_2024_features_cleaned['은행'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "# 기존 인코더에 \"기타\" 값을 추가하여 인코딩\n",
    "if '기타' not in label_encoder_계좌적요.classes_:\n",
    "    label_encoder_계좌적요.classes_ = np.append(label_encoder_계좌적요.classes_, '기타')\n",
    "if '기타' not in label_encoder_은행.classes_:\n",
    "    label_encoder_은행.classes_ = np.append(label_encoder_은행.classes_, '기타')\n",
    "\n",
    "# 변환\n",
    "df_2024_features_cleaned['계좌적요'] = label_encoder_계좌적요.transform(df_2024_features_cleaned['계좌적요'])\n",
    "df_2024_features_cleaned['은행'] = label_encoder_은행.transform(df_2024_features_cleaned['은행'])\n",
    "\n",
    "# '용도' 예측 수행\n",
    "y_2024_pred = voting_clf.predict(df_2024_features_cleaned)\n",
    "\n",
    "# 예측된 '용도'를 원래 값으로 디코딩\n",
    "y_2024_pred_original = label_encoder_용도.inverse_transform(y_2024_pred)\n",
    "\n",
    "# 예측된 '용도'를 원래 데이터에 추가 (결측치 제거된 데이터만 사용)\n",
    "df_2024_cleaned['예측용도'] = y_2024_pred_original\n",
    "\n",
    "# 예측 결과를 엑셀로 저장\n",
    "output_file_2024 = os.path.join(company_result_root, f'{company_name}_입금내역_용도_예측(2024).xlsx')\n",
    "df_2024_cleaned[['입금일자', '입금액', '계좌적요', '은행', '예측용도']].to_excel(output_file_2024, index=False)\n",
    "print('2024년 예측 결과가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2) 입금 파일 : '거래처' Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Progress:\n",
      "[0]\tvalidation_0-mlogloss:2.21602\n",
      "[1]\tvalidation_0-mlogloss:1.23352\n",
      "[2]\tvalidation_0-mlogloss:0.87298\n",
      "[3]\tvalidation_0-mlogloss:0.64612\n",
      "[4]\tvalidation_0-mlogloss:0.48912\n",
      "[5]\tvalidation_0-mlogloss:0.37515\n",
      "[6]\tvalidation_0-mlogloss:0.29259\n",
      "[7]\tvalidation_0-mlogloss:0.23157\n",
      "[8]\tvalidation_0-mlogloss:0.18686\n",
      "[9]\tvalidation_0-mlogloss:0.15250\n",
      "[10]\tvalidation_0-mlogloss:0.12679\n",
      "[11]\tvalidation_0-mlogloss:0.10745\n",
      "[12]\tvalidation_0-mlogloss:0.09279\n",
      "[13]\tvalidation_0-mlogloss:0.08165\n",
      "[14]\tvalidation_0-mlogloss:0.07285\n",
      "[15]\tvalidation_0-mlogloss:0.06655\n",
      "[16]\tvalidation_0-mlogloss:0.06240\n",
      "[17]\tvalidation_0-mlogloss:0.05982\n",
      "[18]\tvalidation_0-mlogloss:0.05809\n",
      "[19]\tvalidation_0-mlogloss:0.05690\n",
      "[20]\tvalidation_0-mlogloss:0.05605\n",
      "[21]\tvalidation_0-mlogloss:0.05541\n",
      "[22]\tvalidation_0-mlogloss:0.05491\n",
      "[23]\tvalidation_0-mlogloss:0.05444\n",
      "[24]\tvalidation_0-mlogloss:0.05403\n",
      "[25]\tvalidation_0-mlogloss:0.05370\n",
      "[26]\tvalidation_0-mlogloss:0.05334\n",
      "[27]\tvalidation_0-mlogloss:0.05296\n",
      "[28]\tvalidation_0-mlogloss:0.05265\n",
      "[29]\tvalidation_0-mlogloss:0.05242\n",
      "[30]\tvalidation_0-mlogloss:0.05214\n",
      "[31]\tvalidation_0-mlogloss:0.05195\n",
      "[32]\tvalidation_0-mlogloss:0.05177\n",
      "[33]\tvalidation_0-mlogloss:0.05159\n",
      "[34]\tvalidation_0-mlogloss:0.05144\n",
      "[35]\tvalidation_0-mlogloss:0.05129\n",
      "[36]\tvalidation_0-mlogloss:0.05110\n",
      "[37]\tvalidation_0-mlogloss:0.05099\n",
      "[38]\tvalidation_0-mlogloss:0.05079\n",
      "[39]\tvalidation_0-mlogloss:0.05070\n",
      "[40]\tvalidation_0-mlogloss:0.05059\n",
      "[41]\tvalidation_0-mlogloss:0.05046\n",
      "[42]\tvalidation_0-mlogloss:0.05031\n",
      "[43]\tvalidation_0-mlogloss:0.05022\n",
      "[44]\tvalidation_0-mlogloss:0.05011\n",
      "[45]\tvalidation_0-mlogloss:0.05004\n",
      "[46]\tvalidation_0-mlogloss:0.04994\n",
      "[47]\tvalidation_0-mlogloss:0.04985\n",
      "[48]\tvalidation_0-mlogloss:0.04976\n",
      "[49]\tvalidation_0-mlogloss:0.04969\n",
      "[50]\tvalidation_0-mlogloss:0.04958\n",
      "[51]\tvalidation_0-mlogloss:0.04949\n",
      "[52]\tvalidation_0-mlogloss:0.04945\n",
      "[53]\tvalidation_0-mlogloss:0.04933\n",
      "[54]\tvalidation_0-mlogloss:0.04927\n",
      "[55]\tvalidation_0-mlogloss:0.04922\n",
      "[56]\tvalidation_0-mlogloss:0.04915\n",
      "[57]\tvalidation_0-mlogloss:0.04908\n",
      "[58]\tvalidation_0-mlogloss:0.04898\n",
      "[59]\tvalidation_0-mlogloss:0.04894\n",
      "[60]\tvalidation_0-mlogloss:0.04884\n",
      "[61]\tvalidation_0-mlogloss:0.04879\n",
      "[62]\tvalidation_0-mlogloss:0.04873\n",
      "[63]\tvalidation_0-mlogloss:0.04869\n",
      "[64]\tvalidation_0-mlogloss:0.04863\n",
      "[65]\tvalidation_0-mlogloss:0.04860\n",
      "[66]\tvalidation_0-mlogloss:0.04854\n",
      "[67]\tvalidation_0-mlogloss:0.04851\n",
      "[68]\tvalidation_0-mlogloss:0.04844\n",
      "[69]\tvalidation_0-mlogloss:0.04839\n",
      "[70]\tvalidation_0-mlogloss:0.04834\n",
      "[71]\tvalidation_0-mlogloss:0.04827\n",
      "[72]\tvalidation_0-mlogloss:0.04823\n",
      "[73]\tvalidation_0-mlogloss:0.04815\n",
      "[74]\tvalidation_0-mlogloss:0.04810\n",
      "[75]\tvalidation_0-mlogloss:0.04807\n",
      "[76]\tvalidation_0-mlogloss:0.04798\n",
      "[77]\tvalidation_0-mlogloss:0.04797\n",
      "[78]\tvalidation_0-mlogloss:0.04793\n",
      "[79]\tvalidation_0-mlogloss:0.04789\n",
      "[80]\tvalidation_0-mlogloss:0.04786\n",
      "[81]\tvalidation_0-mlogloss:0.04779\n",
      "[82]\tvalidation_0-mlogloss:0.04776\n",
      "[83]\tvalidation_0-mlogloss:0.04771\n",
      "[84]\tvalidation_0-mlogloss:0.04768\n",
      "[85]\tvalidation_0-mlogloss:0.04766\n",
      "[86]\tvalidation_0-mlogloss:0.04760\n",
      "[87]\tvalidation_0-mlogloss:0.04759\n",
      "[88]\tvalidation_0-mlogloss:0.04757\n",
      "[89]\tvalidation_0-mlogloss:0.04754\n",
      "[90]\tvalidation_0-mlogloss:0.04748\n",
      "[91]\tvalidation_0-mlogloss:0.04746\n",
      "[92]\tvalidation_0-mlogloss:0.04742\n",
      "[93]\tvalidation_0-mlogloss:0.04740\n",
      "[94]\tvalidation_0-mlogloss:0.04736\n",
      "[95]\tvalidation_0-mlogloss:0.04737\n",
      "[96]\tvalidation_0-mlogloss:0.04732\n",
      "[97]\tvalidation_0-mlogloss:0.04730\n",
      "[98]\tvalidation_0-mlogloss:0.04725\n",
      "[99]\tvalidation_0-mlogloss:0.04722\n",
      "RandomForest Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest Training: 100%|██████████| 100/100 [00:26<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training: 100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# '입금일자'를 datetime 형식으로 변환\n",
    "df['입금일자'] = pd.to_datetime(df['입금일자'], errors='coerce')\n",
    "\n",
    "# 필터링할 최종 날짜 설정 (2024년 4월 30일)\n",
    "end_date = pd.Timestamp('2024-04-30')\n",
    "\n",
    "# '입금일자'가 end_date 이하인 데이터만 필터링\n",
    "filtered_df = df[df['입금일자'] <= end_date].copy()\n",
    "\n",
    "# '거래처'와 '상대계좌예금주명(비고)'이 동일한지 여부를 나타내는 특성 생성\n",
    "filtered_df['거래처_상대계좌일치'] = filtered_df.apply(\n",
    "    lambda row: 1 if pd.notna(row['거래처']) and pd.notna(row['비고']) and row['거래처'] in row['비고'] else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 예측에 사용할 특성 선택\n",
    "filtered_df_pred = filtered_df[['입금액', '계좌적요', '은행', '용도', '거래처', '거래처_상대계좌일치']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거\n",
    "cleaned_df = filtered_df_pred.dropna().copy()\n",
    "\n",
    "# 클래스별 데이터 개수 확인\n",
    "class_counts = cleaned_df['거래처'].value_counts()\n",
    "\n",
    "# 클래스 수가 2개 미만인 클래스 제거\n",
    "min_class_count = 2\n",
    "classes_to_keep = class_counts[class_counts >= min_class_count].index\n",
    "cleaned_df_filtered = cleaned_df[cleaned_df['거래처'].isin(classes_to_keep)].copy()\n",
    "\n",
    "# 다시 X와 y 정의\n",
    "X = cleaned_df_filtered[['입금액', '계좌적요', '거래처_상대계좌일치']].copy()\n",
    "y = cleaned_df_filtered['거래처'].copy()\n",
    "\n",
    "# 범주형 변수(Label Encoding) 변환 (클래수 제거 후 적용)\n",
    "label_encoder_계좌적요 = LabelEncoder()\n",
    "label_encoder_일치여부 = LabelEncoder()\n",
    "label_encoder_거래처 = LabelEncoder()\n",
    "\n",
    "# Fit Transform\n",
    "X['계좌적요'] = label_encoder_계좌적요.fit_transform(X['계좌적요'].copy())\n",
    "X['거래처_상대계좌일치'] = label_encoder_일치여부.fit_transform(X['거래처_상대계좌일치'].copy())\n",
    "y = label_encoder_거래처.fit_transform(y.copy())\n",
    "\n",
    "# 데이터셋을 stratify를 사용해 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 클래스 불균형 문제를 해결하기 위해 Random Over Sampling 적용\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링한 학습 데이터에서 20%를 검증 데이터로 분리 (eval_set용)\n",
    "X_train_ros, X_val_ros, y_train_ros, y_val_ros = train_test_split(\n",
    "    X_train_ros, y_train_ros, test_size=0.2, random_state=42, stratify=y_train_ros\n",
    ")\n",
    "\n",
    "# XGBoost 모델 학습 (eval_set을 사용해 성능 모니터링)\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss')\n",
    "\n",
    "print('XGBoost Training Progress:')\n",
    "xgb_model.fit(X_train_ros, y_train_ros, eval_set=[(X_val_ros, y_val_ros)])\n",
    "\n",
    "# RandomForest 모델 학습 시 tqdm 진행률 표시\n",
    "n_estimators = 100\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "print('RandomForest Training Progress:')\n",
    "for i in tqdm(range(1, n_estimators + 1), desc='RandomForest Training'):\n",
    "    rf_model.set_params(n_estimators=i)\n",
    "    rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Voting Classifier 생성 (XGBoost + RandomForest)\n",
    "voting_clf = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "# Voting Classifier 학습 시 tqdm 진행률 표시\n",
    "print('Voting Classifier Training Progress:')\n",
    "for _ in tqdm(range(1), desc='Voting Classifier Training'):\n",
    "    voting_clf.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.906\n"
     ]
    }
   ],
   "source": [
    "# XGBoost + RandomForest Ensemble Result\n",
    "# LabelEncoder로 예측된 값을 다시 원래 값으로 디코딩\n",
    "y_test_original = label_encoder_거래처.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder_거래처.inverse_transform(y_pred)\n",
    "\n",
    "# Classification_report를 Dictionary로 변환\n",
    "report = classification_report(y_test_original, y_pred_original, zero_division=1, output_dict=True)\n",
    "\n",
    "# Accuracy만 출력\n",
    "accuracy = round(report['accuracy'], 3)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# classification_report를 데이터프레임으로 변환하고 엑셀로 저장하는 간단한 코드\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 소수점 3자리로 변환\n",
    "report_df = report_df.round(3)\n",
    "\n",
    "# 회사명에 따른 결과물 저장 경로\n",
    "result_root = os.path.join(root, 'Model(1st)')\n",
    "company_result_root = os.path.join(result_root, company_name)\n",
    "if not os.path.isdir(company_result_root):\n",
    "    os.makedirs(company_result_root)\n",
    "\n",
    "# 결과물 최종 경로\n",
    "output_file = os.path.join(company_result_root, f'{company_name}_입금내역_거래처.xlsx')\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "report_df.to_excel(output_file, index=True)\n",
    "print('Classification Report가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 예측 결과가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2024년 Data 예측 #\n",
    "\n",
    "# '입금일자'를 datetime 형식으로 변환하고 2024년 데이터를 필터링\n",
    "df_2024 = df[df['입금일자'].dt.year == 2024].copy()\n",
    "\n",
    "# '거래처'와 '상대계좌예금주명(비고)'이 동일한지 여부를 나타내는 특성 생성\n",
    "df_2024['거래처_상대계좌일치'] = df_2024.apply(\n",
    "    lambda row: 1 if pd.notna(row['거래처']) and pd.notna(row['비고']) and row['거래처'] in row['비고'] else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 예측에 필요한 컬럼만 선택\n",
    "df_2024_features = df_2024[['입금액', '계좌적요', '거래처_상대계좌일치']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거 (원본 데이터에서 인덱스 추적)\n",
    "df_2024_features_cleaned = df_2024_features.dropna().copy()\n",
    "df_2024_cleaned = df_2024.loc[df_2024_features_cleaned.index].copy()\n",
    "\n",
    "# 라벨 인코딩 (기존에 학습된 인코더 사용)\n",
    "# 새로운 값을 처리하기 위해 np.where를 사용해 학습 데이터에 없는 값은 '기타'로 처리\n",
    "df_2024_features_cleaned['계좌적요'] = np.where(\n",
    "    df_2024_features_cleaned['계좌적요'].isin(label_encoder_계좌적요.classes_),\n",
    "    df_2024_features_cleaned['계좌적요'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "df_2024_features_cleaned['거래처_상대계좌일치'] = np.where(\n",
    "    df_2024_features_cleaned['거래처_상대계좌일치'].isin(label_encoder_일치여부.classes_),\n",
    "    df_2024_features_cleaned['거래처_상대계좌일치'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "# 기존 인코더에 '기타' 값을 추가하여 인코딩\n",
    "if '기타' not in label_encoder_계좌적요.classes_:\n",
    "    label_encoder_계좌적요.classes_ = np.append(label_encoder_계좌적요.classes_, '기타')\n",
    "\n",
    "if '기타' not in label_encoder_일치여부.classes_:\n",
    "    label_encoder_일치여부.classes_ = np.append(label_encoder_일치여부.classes_, '기타')\n",
    "\n",
    "# 변환\n",
    "df_2024_features_cleaned['계좌적요'] = label_encoder_계좌적요.transform(df_2024_features_cleaned['계좌적요'])\n",
    "df_2024_features_cleaned['거래처_상대계좌일치'] = label_encoder_일치여부.transform(df_2024_features_cleaned['거래처_상대계좌일치'])\n",
    "\n",
    "# '거래처' 예측 수행\n",
    "y_2024_pred = voting_clf.predict(df_2024_features_cleaned)\n",
    "\n",
    "# 예측된 '거래처'를 원래 값으로 디코딩\n",
    "y_2024_pred_original = label_encoder_거래처.inverse_transform(y_2024_pred)\n",
    "\n",
    "# 예측된 '거래처'를 원래 데이터에 추가 (결측치 제거된 데이터만 사용)\n",
    "df_2024_cleaned['예측거래처'] = y_2024_pred_original\n",
    "\n",
    "# 예측 결과를 엑셀로 저장\n",
    "output_file_2024 = os.path.join(company_result_root, f'{company_name}_입금내역_거래처_예측(2024).xlsx')\n",
    "df_2024_cleaned[['입금일자', '입금액', '계좌적요', '거래처_상대계좌일치', '예측거래처']].to_excel(output_file_2024, index=False)\n",
    "print('2024년 예측 결과가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. 출금내역 Data Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>출금일자</th>\n",
       "      <th>은행</th>\n",
       "      <th>출금액</th>\n",
       "      <th>용도</th>\n",
       "      <th>프로젝트/현장</th>\n",
       "      <th>비고</th>\n",
       "      <th>메모</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>993800</td>\n",
       "      <td>매입대금지급</td>\n",
       "      <td>NaN</td>\n",
       "      <td>결의서_202312_19\\n2023-12-28 세계 수수료 500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>880500</td>\n",
       "      <td>매입대금지급</td>\n",
       "      <td>NaN</td>\n",
       "      <td>결의서_202312_18\\n2023-12-27 세계 수수료 500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>286500</td>\n",
       "      <td>매입대금지급</td>\n",
       "      <td>NaN</td>\n",
       "      <td>결의서_202312_17\\n2023-12-26 세계 수수료 500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>195560</td>\n",
       "      <td>매입대금지급</td>\n",
       "      <td>NaN</td>\n",
       "      <td>결의서_202312_16\\n결의서_202312_16\\n2023-12-18 세계202...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>우리은행</td>\n",
       "      <td>200000</td>\n",
       "      <td>일반경조사비</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           출금일자    은행     출금액      용도  프로젝트/현장  \\\n",
       "181  2023-12-29  우리은행  993800  매입대금지급      NaN   \n",
       "182  2023-12-29  우리은행  880500  매입대금지급      NaN   \n",
       "183  2023-12-29  우리은행  286500  매입대금지급      NaN   \n",
       "184  2023-12-29  우리은행  195560  매입대금지급      NaN   \n",
       "185  2023-12-27  우리은행  200000  일반경조사비      NaN   \n",
       "\n",
       "                                                    비고  메모  \n",
       "181               결의서_202312_19\\n2023-12-28 세계 수수료 500 NaN  \n",
       "182               결의서_202312_18\\n2023-12-27 세계 수수료 500 NaN  \n",
       "183               결의서_202312_17\\n2023-12-26 세계 수수료 500 NaN  \n",
       "184  결의서_202312_16\\n결의서_202312_16\\n2023-12-18 세계202... NaN  \n",
       "185                                                NaN NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '출금내역_지급확인' 파일명\n",
    "file_name = [file for file in os.listdir() if '출금내역_지급확인' in file] # 출금내역 파일 1개\n",
    "\n",
    "# Data Frame\n",
    "df = pd.read_excel(file_name[0], skiprows=1)\n",
    "\n",
    "# Data Frame Head(2023)\n",
    "df_without_account = df.drop(columns=['계좌번호', '계좌적요', '거래처', '내용'])\n",
    "df_without_account[df_without_account['출금일자'].str.contains('2023-12')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1) 출금 파일 : '용도' Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Progress:\n",
      "[0]\tvalidation_0-mlogloss:0.81608\n",
      "[1]\tvalidation_0-mlogloss:0.58970\n",
      "[2]\tvalidation_0-mlogloss:0.45281\n",
      "[3]\tvalidation_0-mlogloss:0.35570\n",
      "[4]\tvalidation_0-mlogloss:0.28036\n",
      "[5]\tvalidation_0-mlogloss:0.22655\n",
      "[6]\tvalidation_0-mlogloss:0.18822\n",
      "[7]\tvalidation_0-mlogloss:0.15922\n",
      "[8]\tvalidation_0-mlogloss:0.13632\n",
      "[9]\tvalidation_0-mlogloss:0.11910\n",
      "[10]\tvalidation_0-mlogloss:0.10564\n",
      "[11]\tvalidation_0-mlogloss:0.09606\n",
      "[12]\tvalidation_0-mlogloss:0.08823\n",
      "[13]\tvalidation_0-mlogloss:0.08198\n",
      "[14]\tvalidation_0-mlogloss:0.07689\n",
      "[15]\tvalidation_0-mlogloss:0.07299\n",
      "[16]\tvalidation_0-mlogloss:0.06999\n",
      "[17]\tvalidation_0-mlogloss:0.06764\n",
      "[18]\tvalidation_0-mlogloss:0.06547\n",
      "[19]\tvalidation_0-mlogloss:0.06398\n",
      "[20]\tvalidation_0-mlogloss:0.06276\n",
      "[21]\tvalidation_0-mlogloss:0.06176\n",
      "[22]\tvalidation_0-mlogloss:0.06091\n",
      "[23]\tvalidation_0-mlogloss:0.06022\n",
      "[24]\tvalidation_0-mlogloss:0.05960\n",
      "[25]\tvalidation_0-mlogloss:0.05911\n",
      "[26]\tvalidation_0-mlogloss:0.05864\n",
      "[27]\tvalidation_0-mlogloss:0.05840\n",
      "[28]\tvalidation_0-mlogloss:0.05800\n",
      "[29]\tvalidation_0-mlogloss:0.05779\n",
      "[30]\tvalidation_0-mlogloss:0.05757\n",
      "[31]\tvalidation_0-mlogloss:0.05731\n",
      "[32]\tvalidation_0-mlogloss:0.05711\n",
      "[33]\tvalidation_0-mlogloss:0.05693\n",
      "[34]\tvalidation_0-mlogloss:0.05678\n",
      "[35]\tvalidation_0-mlogloss:0.05663\n",
      "[36]\tvalidation_0-mlogloss:0.05650\n",
      "[37]\tvalidation_0-mlogloss:0.05642\n",
      "[38]\tvalidation_0-mlogloss:0.05633\n",
      "[39]\tvalidation_0-mlogloss:0.05625\n",
      "[40]\tvalidation_0-mlogloss:0.05622\n",
      "[41]\tvalidation_0-mlogloss:0.05618\n",
      "[42]\tvalidation_0-mlogloss:0.05608\n",
      "[43]\tvalidation_0-mlogloss:0.05602\n",
      "[44]\tvalidation_0-mlogloss:0.05597\n",
      "[45]\tvalidation_0-mlogloss:0.05592\n",
      "[46]\tvalidation_0-mlogloss:0.05587\n",
      "[47]\tvalidation_0-mlogloss:0.05583\n",
      "[48]\tvalidation_0-mlogloss:0.05573\n",
      "[49]\tvalidation_0-mlogloss:0.05564\n",
      "[50]\tvalidation_0-mlogloss:0.05559\n",
      "[51]\tvalidation_0-mlogloss:0.05549\n",
      "[52]\tvalidation_0-mlogloss:0.05546\n",
      "[53]\tvalidation_0-mlogloss:0.05539\n",
      "[54]\tvalidation_0-mlogloss:0.05532\n",
      "[55]\tvalidation_0-mlogloss:0.05525\n",
      "[56]\tvalidation_0-mlogloss:0.05526\n",
      "[57]\tvalidation_0-mlogloss:0.05524\n",
      "[58]\tvalidation_0-mlogloss:0.05522\n",
      "[59]\tvalidation_0-mlogloss:0.05516\n",
      "[60]\tvalidation_0-mlogloss:0.05512\n",
      "[61]\tvalidation_0-mlogloss:0.05512\n",
      "[62]\tvalidation_0-mlogloss:0.05509\n",
      "[63]\tvalidation_0-mlogloss:0.05507\n",
      "[64]\tvalidation_0-mlogloss:0.05510\n",
      "[65]\tvalidation_0-mlogloss:0.05507\n",
      "[66]\tvalidation_0-mlogloss:0.05508\n",
      "[67]\tvalidation_0-mlogloss:0.05505\n",
      "[68]\tvalidation_0-mlogloss:0.05506\n",
      "[69]\tvalidation_0-mlogloss:0.05506\n",
      "[70]\tvalidation_0-mlogloss:0.05501\n",
      "[71]\tvalidation_0-mlogloss:0.05498\n",
      "[72]\tvalidation_0-mlogloss:0.05493\n",
      "[73]\tvalidation_0-mlogloss:0.05492\n",
      "[74]\tvalidation_0-mlogloss:0.05493\n",
      "[75]\tvalidation_0-mlogloss:0.05490\n",
      "[76]\tvalidation_0-mlogloss:0.05490\n",
      "[77]\tvalidation_0-mlogloss:0.05484\n",
      "[78]\tvalidation_0-mlogloss:0.05483\n",
      "[79]\tvalidation_0-mlogloss:0.05482\n",
      "[80]\tvalidation_0-mlogloss:0.05481\n",
      "[81]\tvalidation_0-mlogloss:0.05480\n",
      "[82]\tvalidation_0-mlogloss:0.05482\n",
      "[83]\tvalidation_0-mlogloss:0.05483\n",
      "[84]\tvalidation_0-mlogloss:0.05483\n",
      "[85]\tvalidation_0-mlogloss:0.05481\n",
      "[86]\tvalidation_0-mlogloss:0.05480\n",
      "[87]\tvalidation_0-mlogloss:0.05479\n",
      "[88]\tvalidation_0-mlogloss:0.05481\n",
      "[89]\tvalidation_0-mlogloss:0.05479\n",
      "[90]\tvalidation_0-mlogloss:0.05478\n",
      "[91]\tvalidation_0-mlogloss:0.05477\n",
      "[92]\tvalidation_0-mlogloss:0.05477\n",
      "[93]\tvalidation_0-mlogloss:0.05475\n",
      "[94]\tvalidation_0-mlogloss:0.05476\n",
      "[95]\tvalidation_0-mlogloss:0.05473\n",
      "[96]\tvalidation_0-mlogloss:0.05468\n",
      "[97]\tvalidation_0-mlogloss:0.05469\n",
      "[98]\tvalidation_0-mlogloss:0.05470\n",
      "[99]\tvalidation_0-mlogloss:0.05467\n",
      "RandomForest Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest Training: 100%|██████████| 100/100 [00:15<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# '출금일자'를 datetime 형식으로 변환하고 2023년까지 필터링\n",
    "df['출금일자'] = pd.to_datetime(df['출금일자'], errors='coerce')\n",
    "df_filtered = df[df['출금일자'].dt.year <= 2023].copy()\n",
    "\n",
    "# '용도'와 '거래처'의 결측치가 있는 행 제거\n",
    "df_filtered_cleaned = df_filtered.dropna(subset=['용도', '거래처']).copy()\n",
    "\n",
    "# 예측에 사용할 특성 선택\n",
    "df_features = df_filtered_cleaned[['출금액', '계좌적요', '은행', '용도', '거래처']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거\n",
    "df_features_cleaned = df_features.dropna().copy()\n",
    "\n",
    "# 클래스별 데이터 개수 확인\n",
    "class_counts = df_features_cleaned['용도'].value_counts()\n",
    "\n",
    "# 클래스 수가 2개 미만인 클래스 제거\n",
    "min_class_count = 2\n",
    "classes_to_keep = class_counts[class_counts >= min_class_count].index\n",
    "df_filtered_cleaned = df_features_cleaned[df_features_cleaned['용도'].isin(classes_to_keep)].copy()\n",
    "\n",
    "# 다시 X와 y 정의\n",
    "X = df_filtered_cleaned[['출금액', '계좌적요', '은행']].copy()\n",
    "y = df_filtered_cleaned['용도'].copy()\n",
    "\n",
    "# 범주형 변수(Label Encoding) 변환 (클래스 제거 후 적용)\n",
    "label_encoder_계좌적요 = LabelEncoder()\n",
    "label_encoder_은행 = LabelEncoder()\n",
    "label_encoder_용도 = LabelEncoder()\n",
    "\n",
    "# Fit Transform\n",
    "X['계좌적요'] = label_encoder_계좌적요.fit_transform(X['계좌적요'].copy())\n",
    "X['은행'] = label_encoder_은행.fit_transform(X['은행'].copy())\n",
    "y = label_encoder_용도.fit_transform(y.copy())\n",
    "\n",
    "# 데이터셋을 stratify를 사용해 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 클래스 불균형 문제를 해결하기 위해 Random Over Sampling 적용\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링한 학습 데이터에서 20%를 검증 데이터로 분리 (eval_set용)\n",
    "X_train_ros, X_val_ros, y_train_ros, y_val_ros = train_test_split(\n",
    "    X_train_ros, y_train_ros, test_size=0.2, random_state=42, stratify=y_train_ros\n",
    ")\n",
    "\n",
    "# XGBoost 모델 학습 (eval_set을 사용해 성능 모니터링)\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss')\n",
    "\n",
    "print('XGBoost Training Progress:')\n",
    "xgb_model.fit(X_train_ros, y_train_ros, eval_set=[(X_val_ros, y_val_ros)])\n",
    "\n",
    "# RandomForest 모델 학습 시 tqdm 진행률 표시\n",
    "n_estimators = 100\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "print('RandomForest Training Progress:')\n",
    "for i in tqdm(range(1, n_estimators + 1), desc='RandomForest Training'):\n",
    "    rf_model.set_params(n_estimators=i)\n",
    "    rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Voting Classifier 생성 (XGBoost + RandomForest)\n",
    "voting_clf = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "# Voting Classifier 학습 시 tqdm 진행률 표시\n",
    "print('Voting Classifier Training Progress:')\n",
    "for _ in tqdm(range(1), desc='Voting Classifier Training'):\n",
    "    voting_clf.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "# XGBoost + RandomForest Ensemble Result\n",
    "# LabelEncoder로 예측된 값을 다시 원래 값으로 디코딩\n",
    "y_test_original = label_encoder_용도.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder_용도.inverse_transform(y_pred)\n",
    "\n",
    "# Classification_report를 Dictionary로 변환\n",
    "report = classification_report(y_test_original, y_pred_original, zero_division=1, output_dict=True)\n",
    "\n",
    "# Accuracy만 출력\n",
    "accuracy = round(report['accuracy'], 3)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# classification_report를 데이터프레임으로 변환하고 엑셀로 저장하는 간단한 코드\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 소수점 3자리로 변환\n",
    "report_df = report_df.round(3)\n",
    "\n",
    "# 회사명에 따른 결과물 저장 경로\n",
    "result_root = os.path.join(root, 'Model(1st)')\n",
    "company_result_root = os.path.join(result_root, company_name)\n",
    "if not os.path.isdir(company_result_root):\n",
    "    os.makedirs(company_result_root)\n",
    "\n",
    "# 결과물 최종 경로\n",
    "output_file = os.path.join(company_result_root, f'{company_name}_출금내역_용도.xlsx')\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "report_df.to_excel(output_file, index=True)\n",
    "print('Classification Report가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 예측 결과가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2024년 Data 예측 #\n",
    "\n",
    "# '출금일자'를 datetime 형식으로 변환하고 2024년 필터링\n",
    "df_2024 = df[df['출금일자'].dt.year == 2024].copy()\n",
    "\n",
    "# 예측에 필요한 컬럼만 선택\n",
    "df_2024_features = df_2024[['출금액', '계좌적요', '은행']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거 (원본 데이터에서 인덱스 추적)\n",
    "df_2024_features_cleaned = df_2024_features.dropna().copy()\n",
    "df_2024_cleaned = df_2024.loc[df_2024_features_cleaned.index].copy()\n",
    "\n",
    "# 라벨 인코딩 (기존에 학습된 인코더 사용)\n",
    "# 새로운 값을 처리하기 위해 np.where를 사용해 학습 데이터에 없는 값은 \"기타\"로 처리\n",
    "df_2024_features_cleaned['계좌적요'] = np.where(\n",
    "    df_2024_features_cleaned['계좌적요'].isin(label_encoder_계좌적요.classes_),\n",
    "    df_2024_features_cleaned['계좌적요'],\n",
    "    '기타'\n",
    ")\n",
    "df_2024_features_cleaned['은행'] = np.where(\n",
    "    df_2024_features_cleaned['은행'].isin(label_encoder_은행.classes_),\n",
    "    df_2024_features_cleaned['은행'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "# 기존 인코더에 \"기타\" 값을 추가하여 인코딩\n",
    "if '기타' not in label_encoder_계좌적요.classes_:\n",
    "    label_encoder_계좌적요.classes_ = np.append(label_encoder_계좌적요.classes_, '기타')\n",
    "if '기타' not in label_encoder_은행.classes_:\n",
    "    label_encoder_은행.classes_ = np.append(label_encoder_은행.classes_, '기타')\n",
    "\n",
    "# 변환\n",
    "df_2024_features_cleaned['계좌적요'] = label_encoder_계좌적요.transform(df_2024_features_cleaned['계좌적요'])\n",
    "df_2024_features_cleaned['은행'] = label_encoder_은행.transform(df_2024_features_cleaned['은행'])\n",
    "\n",
    "# '용도' 예측 수행\n",
    "y_2024_pred = voting_clf.predict(df_2024_features_cleaned)\n",
    "\n",
    "# 예측된 '용도'를 원래 값으로 디코딩\n",
    "y_2024_pred_original = label_encoder_용도.inverse_transform(y_2024_pred)\n",
    "\n",
    "# 예측된 '용도'를 원래 데이터에 추가 (결측치 제거된 데이터만 사용)\n",
    "df_2024_cleaned['예측용도'] = y_2024_pred_original\n",
    "\n",
    "# 예측 결과를 엑셀로 저장\n",
    "output_file_2024 = os.path.join(company_result_root, f'{company_name}_출금내역_용도_예측(2024).xlsx')\n",
    "df_2024_cleaned[['출금일자', '출금액', '계좌적요', '은행', '예측용도']].to_excel(output_file_2024, index=False)\n",
    "print('2024년 예측 결과가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2) 출금 파일 : '거래처' Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Progress:\n",
      "[0]\tvalidation_0-mlogloss:1.02428\n",
      "[1]\tvalidation_0-mlogloss:0.75184\n",
      "[2]\tvalidation_0-mlogloss:0.58615\n",
      "[3]\tvalidation_0-mlogloss:0.47362\n",
      "[4]\tvalidation_0-mlogloss:0.39290\n",
      "[5]\tvalidation_0-mlogloss:0.33351\n",
      "[6]\tvalidation_0-mlogloss:0.29004\n",
      "[7]\tvalidation_0-mlogloss:0.25657\n",
      "[8]\tvalidation_0-mlogloss:0.23201\n",
      "[9]\tvalidation_0-mlogloss:0.21277\n",
      "[10]\tvalidation_0-mlogloss:0.19803\n",
      "[11]\tvalidation_0-mlogloss:0.18676\n",
      "[12]\tvalidation_0-mlogloss:0.17778\n",
      "[13]\tvalidation_0-mlogloss:0.17091\n",
      "[14]\tvalidation_0-mlogloss:0.16562\n",
      "[15]\tvalidation_0-mlogloss:0.16114\n",
      "[16]\tvalidation_0-mlogloss:0.15740\n",
      "[17]\tvalidation_0-mlogloss:0.15464\n",
      "[18]\tvalidation_0-mlogloss:0.15217\n",
      "[19]\tvalidation_0-mlogloss:0.15027\n",
      "[20]\tvalidation_0-mlogloss:0.14843\n",
      "[21]\tvalidation_0-mlogloss:0.14694\n",
      "[22]\tvalidation_0-mlogloss:0.14593\n",
      "[23]\tvalidation_0-mlogloss:0.14501\n",
      "[24]\tvalidation_0-mlogloss:0.14430\n",
      "[25]\tvalidation_0-mlogloss:0.14366\n",
      "[26]\tvalidation_0-mlogloss:0.14318\n",
      "[27]\tvalidation_0-mlogloss:0.14276\n",
      "[28]\tvalidation_0-mlogloss:0.14237\n",
      "[29]\tvalidation_0-mlogloss:0.14211\n",
      "[30]\tvalidation_0-mlogloss:0.14179\n",
      "[31]\tvalidation_0-mlogloss:0.14154\n",
      "[32]\tvalidation_0-mlogloss:0.14121\n",
      "[33]\tvalidation_0-mlogloss:0.14095\n",
      "[34]\tvalidation_0-mlogloss:0.14074\n",
      "[35]\tvalidation_0-mlogloss:0.14056\n",
      "[36]\tvalidation_0-mlogloss:0.14034\n",
      "[37]\tvalidation_0-mlogloss:0.14024\n",
      "[38]\tvalidation_0-mlogloss:0.14007\n",
      "[39]\tvalidation_0-mlogloss:0.13986\n",
      "[40]\tvalidation_0-mlogloss:0.13983\n",
      "[41]\tvalidation_0-mlogloss:0.13963\n",
      "[42]\tvalidation_0-mlogloss:0.13948\n",
      "[43]\tvalidation_0-mlogloss:0.13938\n",
      "[44]\tvalidation_0-mlogloss:0.13928\n",
      "[45]\tvalidation_0-mlogloss:0.13919\n",
      "[46]\tvalidation_0-mlogloss:0.13913\n",
      "[47]\tvalidation_0-mlogloss:0.13904\n",
      "[48]\tvalidation_0-mlogloss:0.13896\n",
      "[49]\tvalidation_0-mlogloss:0.13891\n",
      "[50]\tvalidation_0-mlogloss:0.13874\n",
      "[51]\tvalidation_0-mlogloss:0.13869\n",
      "[52]\tvalidation_0-mlogloss:0.13860\n",
      "[53]\tvalidation_0-mlogloss:0.13849\n",
      "[54]\tvalidation_0-mlogloss:0.13845\n",
      "[55]\tvalidation_0-mlogloss:0.13836\n",
      "[56]\tvalidation_0-mlogloss:0.13833\n",
      "[57]\tvalidation_0-mlogloss:0.13824\n",
      "[58]\tvalidation_0-mlogloss:0.13822\n",
      "[59]\tvalidation_0-mlogloss:0.13814\n",
      "[60]\tvalidation_0-mlogloss:0.13812\n",
      "[61]\tvalidation_0-mlogloss:0.13801\n",
      "[62]\tvalidation_0-mlogloss:0.13796\n",
      "[63]\tvalidation_0-mlogloss:0.13786\n",
      "[64]\tvalidation_0-mlogloss:0.13788\n",
      "[65]\tvalidation_0-mlogloss:0.13781\n",
      "[66]\tvalidation_0-mlogloss:0.13777\n",
      "[67]\tvalidation_0-mlogloss:0.13773\n",
      "[68]\tvalidation_0-mlogloss:0.13770\n",
      "[69]\tvalidation_0-mlogloss:0.13766\n",
      "[70]\tvalidation_0-mlogloss:0.13763\n",
      "[71]\tvalidation_0-mlogloss:0.13760\n",
      "[72]\tvalidation_0-mlogloss:0.13757\n",
      "[73]\tvalidation_0-mlogloss:0.13754\n",
      "[74]\tvalidation_0-mlogloss:0.13750\n",
      "[75]\tvalidation_0-mlogloss:0.13749\n",
      "[76]\tvalidation_0-mlogloss:0.13745\n",
      "[77]\tvalidation_0-mlogloss:0.13736\n",
      "[78]\tvalidation_0-mlogloss:0.13731\n",
      "[79]\tvalidation_0-mlogloss:0.13730\n",
      "[80]\tvalidation_0-mlogloss:0.13726\n",
      "[81]\tvalidation_0-mlogloss:0.13725\n",
      "[82]\tvalidation_0-mlogloss:0.13721\n",
      "[83]\tvalidation_0-mlogloss:0.13717\n",
      "[84]\tvalidation_0-mlogloss:0.13713\n",
      "[85]\tvalidation_0-mlogloss:0.13714\n",
      "[86]\tvalidation_0-mlogloss:0.13712\n",
      "[87]\tvalidation_0-mlogloss:0.13709\n",
      "[88]\tvalidation_0-mlogloss:0.13707\n",
      "[89]\tvalidation_0-mlogloss:0.13705\n",
      "[90]\tvalidation_0-mlogloss:0.13703\n",
      "[91]\tvalidation_0-mlogloss:0.13701\n",
      "[92]\tvalidation_0-mlogloss:0.13699\n",
      "[93]\tvalidation_0-mlogloss:0.13696\n",
      "[94]\tvalidation_0-mlogloss:0.13694\n",
      "[95]\tvalidation_0-mlogloss:0.13694\n",
      "[96]\tvalidation_0-mlogloss:0.13690\n",
      "[97]\tvalidation_0-mlogloss:0.13686\n",
      "[98]\tvalidation_0-mlogloss:0.13682\n",
      "[99]\tvalidation_0-mlogloss:0.13680\n",
      "RandomForest Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForest Training: 100%|██████████| 100/100 [00:12<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training: 100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# '출금일자'를 datetime 형식으로 변환하고 2023년까지 필터링\n",
    "df['출금일자'] = pd.to_datetime(df['출금일자'], errors='coerce')\n",
    "filtered_df = df[df['출금일자'].dt.year <= 2023].copy()\n",
    "\n",
    "# '거래처'와 '상대계좌예금주명(비고)'이 동일한지 여부를 나타내는 특성 생성\n",
    "filtered_df['거래처_상대계좌일치'] = filtered_df.apply(\n",
    "    lambda row: 1 if pd.notna(row['거래처']) and pd.notna(row['비고']) and row['거래처'] in row['비고'] else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 예측에 사용할 특성 선택\n",
    "filtered_df_pred = filtered_df[['출금액', '계좌적요', '은행', '용도', '거래처', '거래처_상대계좌일치']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거\n",
    "cleaned_df = filtered_df_pred.dropna().copy()\n",
    "\n",
    "# 클래스별 데이터 개수 확인\n",
    "class_counts = cleaned_df['거래처'].value_counts()\n",
    "\n",
    "# 클래스 수가 2개 미만인 클래스 제거\n",
    "min_class_count = 2\n",
    "classes_to_keep = class_counts[class_counts >= min_class_count].index\n",
    "cleaned_df_filtered = cleaned_df[cleaned_df['거래처'].isin(classes_to_keep)].copy()\n",
    "\n",
    "# 다시 X와 y 정의\n",
    "X = cleaned_df_filtered[['출금액', '계좌적요', '거래처_상대계좌일치']].copy()\n",
    "y = cleaned_df_filtered['거래처'].copy()\n",
    "\n",
    "# 범주형 변수(Label Encoding) 변환 (클래수 제거 후 적용)\n",
    "label_encoder_계좌적요 = LabelEncoder()\n",
    "label_encoder_일치여부 = LabelEncoder()\n",
    "label_encoder_거래처 = LabelEncoder()\n",
    "\n",
    "# Fit Transform\n",
    "X['계좌적요'] = label_encoder_계좌적요.fit_transform(X['계좌적요'].copy())\n",
    "X['거래처_상대계좌일치'] = label_encoder_일치여부.fit_transform(X['거래처_상대계좌일치'].copy())\n",
    "y = label_encoder_거래처.fit_transform(y.copy())\n",
    "\n",
    "# 데이터셋을 stratify를 사용해 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 클래스 불균형 문제를 해결하기 위해 Random Over Sampling 적용\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 오버샘플링한 학습 데이터에서 20%를 검증 데이터로 분리 (eval_set용)\n",
    "X_train_ros, X_val_ros, y_train_ros, y_val_ros = train_test_split(\n",
    "    X_train_ros, y_train_ros, test_size=0.2, random_state=42, stratify=y_train_ros\n",
    ")\n",
    "\n",
    "# XGBoost 모델 학습 (eval_set을 사용해 성능 모니터링)\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='mlogloss')\n",
    "\n",
    "print('XGBoost Training Progress:')\n",
    "xgb_model.fit(X_train_ros, y_train_ros, eval_set=[(X_val_ros, y_val_ros)])\n",
    "\n",
    "# RandomForest 모델 학습 시 tqdm 진행률 표시\n",
    "n_estimators = 100\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "print('RandomForest Training Progress:')\n",
    "for i in tqdm(range(1, n_estimators + 1), desc='RandomForest Training'):\n",
    "    rf_model.set_params(n_estimators=i)\n",
    "    rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Voting Classifier 생성 (XGBoost + RandomForest)\n",
    "voting_clf = VotingClassifier(estimators=[('xgb', xgb_model), ('rf', rf_model)], voting='soft')\n",
    "\n",
    "# Voting Classifier 학습 시 tqdm 진행률 표시\n",
    "print('Voting Classifier Training Progress:')\n",
    "for _ in tqdm(range(1), desc='Voting Classifier Training'):\n",
    "    voting_clf.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "# XGBoost + RandomForest Ensemble Result\n",
    "# LabelEncoder로 예측된 값을 다시 원래 값으로 디코딩\n",
    "y_test_original = label_encoder_거래처.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder_거래처.inverse_transform(y_pred)\n",
    "\n",
    "# Classification_report를 Dictionary로 변환\n",
    "report = classification_report(y_test_original, y_pred_original, zero_division=1, output_dict=True)\n",
    "\n",
    "# Accuracy만 출력\n",
    "accuracy = round(report['accuracy'], 3)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# classification_report를 데이터프레임으로 변환하고 엑셀로 저장하는 간단한 코드\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 소수점 3자리로 변환\n",
    "report_df = report_df.round(3)\n",
    "\n",
    "# 회사명에 따른 결과물 저장 경로\n",
    "result_root = os.path.join(root, 'Model(1st)')\n",
    "company_result_root = os.path.join(result_root, company_name)\n",
    "if not os.path.isdir(company_result_root):\n",
    "    os.makedirs(company_result_root)\n",
    "\n",
    "# 결과물 최종 경로\n",
    "output_file = os.path.join(company_result_root, f'{company_name}_출금내역_거래처.xlsx')\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "report_df.to_excel(output_file, index=True)\n",
    "print('Classification Report가 Excel 파일로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 예측 결과가 Excel 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2024년 Data 예측 #\n",
    "\n",
    "# '출금일자'를 datetime 형식으로 변환하고 2024년 데이터를 필터링\n",
    "df_2024 = df[df['출금일자'].dt.year == 2024].copy()\n",
    "\n",
    "# '거래처'와 '상대계좌예금주명(비고)'이 동일한지 여부를 나타내는 특성 생성\n",
    "df_2024['거래처_상대계좌일치'] = df_2024.apply(\n",
    "    lambda row: 1 if pd.notna(row['거래처']) and pd.notna(row['비고']) and row['거래처'] in row['비고'] else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 예측에 필요한 컬럼만 선택\n",
    "df_2024_features = df_2024[['출금액', '계좌적요', '거래처_상대계좌일치']].copy()\n",
    "\n",
    "# 결측치가 있는 행 제거 (원본 데이터에서 인덱스 추적)\n",
    "df_2024_features_cleaned = df_2024_features.dropna().copy()\n",
    "df_2024_cleaned = df_2024.loc[df_2024_features_cleaned.index].copy()\n",
    "\n",
    "# 라벨 인코딩 (기존에 학습된 인코더 사용)\n",
    "# 새로운 값을 처리하기 위해 np.where를 사용해 학습 데이터에 없는 값은 '기타'로 처리\n",
    "df_2024_features_cleaned['계좌적요'] = np.where(\n",
    "    df_2024_features_cleaned['계좌적요'].isin(label_encoder_계좌적요.classes_),\n",
    "    df_2024_features_cleaned['계좌적요'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "df_2024_features_cleaned['거래처_상대계좌일치'] = np.where(\n",
    "    df_2024_features_cleaned['거래처_상대계좌일치'].isin(label_encoder_일치여부.classes_),\n",
    "    df_2024_features_cleaned['거래처_상대계좌일치'],\n",
    "    '기타'\n",
    ")\n",
    "\n",
    "# 기존 인코더에 '기타' 값을 추가하여 인코딩\n",
    "if '기타' not in label_encoder_계좌적요.classes_:\n",
    "    label_encoder_계좌적요.classes_ = np.append(label_encoder_계좌적요.classes_, '기타')\n",
    "\n",
    "if '기타' not in label_encoder_일치여부.classes_:\n",
    "    label_encoder_일치여부.classes_ = np.append(label_encoder_일치여부.classes_, '기타')\n",
    "\n",
    "# 변환\n",
    "df_2024_features_cleaned['계좌적요'] = label_encoder_계좌적요.transform(df_2024_features_cleaned['계좌적요'])\n",
    "df_2024_features_cleaned['거래처_상대계좌일치'] = label_encoder_일치여부.transform(df_2024_features_cleaned['거래처_상대계좌일치'])\n",
    "\n",
    "# '거래처' 예측 수행\n",
    "y_2024_pred = voting_clf.predict(df_2024_features_cleaned)\n",
    "\n",
    "# 예측된 '거래처'를 원래 값으로 디코딩\n",
    "y_2024_pred_original = label_encoder_거래처.inverse_transform(y_2024_pred)\n",
    "\n",
    "# 예측된 '거래처'를 원래 데이터에 추가 (결측치 제거된 데이터만 사용)\n",
    "df_2024_cleaned['예측거래처'] = y_2024_pred_original\n",
    "\n",
    "# 예측 결과를 엑셀로 저장\n",
    "output_file_2024 = os.path.join(company_result_root, f'{company_name}_출금내역_거래처_예측(2024).xlsx')\n",
    "df_2024_cleaned[['출금일자', '출금액', '계좌적요', '거래처_상대계좌일치', '예측거래처']].to_excel(output_file_2024, index=False)\n",
    "print('2024년 예측 결과가 Excel 파일로 저장되었습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
